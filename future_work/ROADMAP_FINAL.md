# ğŸ¯ LibrarAI - Roadmap de Trabajo Futuro (Consolidado)

**Fecha:** 6 de enero de 2026  
**Basado en:** AnÃ¡lisis de Claude Opus 4.5 + Gemini  
**Enfoque:** Sistema para uso por agente GitHub Copilot (sin UI grÃ¡fica necesaria)

---

## ğŸ“‹ Contexto de Uso

Este sistema serÃ¡ consumido por un **agente de GitHub Copilot** desde VS Code para:

- Redactar apuntes en formato `.md`
- Consultar bibliografÃ­a durante sesiones de escritura
- Generar cÃ³digo y fÃ³rmulas fundamentadas en fuentes

**No se requiere:**

- Web UI (Streamlit/Gradio) â†’ El agente usa CLI o API programÃ¡tica
- VisualizaciÃ³n interactiva de grafos â†’ El agente trabaja con texto
- Streaming visual elaborado â†’ El agente procesa respuestas completas

**SÃ­ se requiere:**

- MÃ¡xima precisiÃ³n en retrieval
- Citas verificables y trazables
- IntegraciÃ³n programÃ¡tica fÃ¡cil (API/CLI robusto)
- Bajo coste operativo (cachÃ©, eficiencia)
- Capacidad de filtrar por dominio/categorÃ­a

---

## ğŸ† LÃ­neas de Trabajo Ordenadas por Impacto

### Escala de Complejidad

| PuntuaciÃ³n | Significado | Tiempo estimado |
| :--------: | :---------- | :-------------- |
|     â­     | Trivial     | < 1 dÃ­a         |
|    â­â­    | Baja        | 1-3 dÃ­as        |
|   â­â­â­   | Media       | 1-2 semanas     |
|  â­â­â­â­  | Alta        | 2-4 semanas     |
| â­â­â­â­â­ | Muy Alta    | > 1 mes         |

---

## ğŸ”´ TIER 1: CrÃ­tico para PrecisiÃ³n (Implementar Primero)

|  #  | LÃ­nea de Trabajo                    | Impacto en PrecisiÃ³n | Mejora que Ofrece                                                                                                                                                                            | Complejidad | Archivos Afectados                          |
| :-: | :---------------------------------- | :------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :------------------------------------------ |
|  1  | **Re-ranking con Cross-Encoder**    | ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯           | +15-25% en precisiÃ³n post-retrieval. RRF es bueno pero un cross-encoder (`ms-marco-MiniLM` o `bge-reranker`) refina eliminando falsos positivos antes de pasar contexto al LLM.              |   â­â­â­    | `fusion.py`, nuevo `reranker.py`            |
|  2  | **Pipeline de EvaluaciÃ³n (RAGAS)**  | ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯           | Base objetiva para medir mejoras. Sin mÃ©tricas (faithfulness, relevancy, context precision) es imposible saber si los cambios mejoran o empeoran el sistema.                                 |   â­â­â­    | Nuevo `src/evaluation/`                     |
|  3  | **CachÃ© de Embeddings**             | ğŸ¯ğŸ¯ğŸ¯ğŸ¯             | Reduce costes 70-90% en queries repetidas y elimina latencia de API. CrÃ­tico para uso intensivo por agente. LRU cache con hash de query.                                                     |   â­â­â­    | `vector_retriever.py`, nuevo `cache.py`     |
|  4  | **Filtrado por CategorÃ­a/Metadata** | ğŸ¯ğŸ¯ğŸ¯ğŸ¯             | Permite queries dirigidas: `"teorÃ­a de grupos" --filter categoria:algebra`. Reduce ruido de dominios no relacionados. La estructura de carpetas ya existe, falta exponer filtros en CLI/API. |   â­â­â­    | `fusion.py`, `ask_library.py`, `indexer.py` |
|  5  | **Qdrant en Docker**                | ğŸ¯ğŸ¯ğŸ¯ğŸ¯             | El sistema actual tiene 125K chunks en modo local (advertencia >20K). DegradaciÃ³n de rendimiento silenciosa. Docker resuelve con persistencia y mejor rendimiento.                           |    â­â­     | `docker-compose.yml`, `settings.yaml`       |

---

## ğŸŸ  TIER 2: Alto Impacto en Calidad de Respuestas

|  #  | LÃ­nea de Trabajo                          | Impacto en PrecisiÃ³n | Mejora que Ofrece                                                                                                                                                                  | Complejidad | Archivos Afectados                           |
| :-: | :---------------------------------------- | :------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :------------------------------------------- |
|  6  | **Query Expansion (HyDE)**                | ğŸ¯ğŸ¯ğŸ¯ğŸ¯             | Hypothetical Document Embeddings: genera respuesta hipotÃ©tica y busca con su embedding. Resuelve desajuste de vocabulario preguntaâ†”documento. Mejora recall en queries abstractas. |   â­â­â­    | `vector_retriever.py`                        |
|  7  | **Pesos DinÃ¡micos segÃºn Query Type**      | ğŸ¯ğŸ¯ğŸ¯ğŸ¯             | El router ya detecta tipo de query pero los pesos son fijos. Query exacta â†’ mÃ¡s BM25. Query conceptual â†’ mÃ¡s Vector. Query relacional â†’ mÃ¡s Graph.                                 |    â­â­     | `router.py`, `fusion.py`                     |
|  8  | **AmpliaciÃ³n de OntologÃ­a (MatemÃ¡ticas)** | ğŸ¯ğŸ¯ğŸ¯ğŸ¯             | `ontology.yaml` solo tiene entidades de cuÃ¡ntica. Faltan: grupos, espacios vectoriales, topologÃ­a, anÃ¡lisis funcional. El grafo actual pierde relaciones matemÃ¡ticas.              |   â­â­â­    | `config/ontology.yaml`, `graph_retriever.py` |
|  9  | **Memoria Conversacional**                | ğŸ¯ğŸ¯ğŸ¯               | Permite preguntas de seguimiento: "Â¿Y si cambio X?", "Expande el punto 3". CrÃ­tico para sesiones de redacciÃ³n de apuntes donde el agente itera.                                    |   â­â­â­    | `ask_library.py`, nuevo `session_manager.py` |
| 10  | **Chunking SemÃ¡ntico Adaptativo**         | ğŸ¯ğŸ¯ğŸ¯               | Detectar lÃ­mites naturales (definiciones, teoremas, demostraciones, ejemplos). Actualmente usa tamaÃ±os fijos que cortan contenido semÃ¡ntico.                                       |  â­â­â­â­   | `chunker.py`                                 |

---

## ğŸŸ¡ TIER 3: Optimizaciones para Uso Intensivo

|  #  | LÃ­nea de Trabajo                       | Impacto en PrecisiÃ³n | Mejora que Ofrece                                                                                                                                               | Complejidad | Archivos Afectados                  |       Estado        |
| :-: | :------------------------------------- | :------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------------------------------- | :-----------------: |
| 11  | **API REST con FastAPI**               | ğŸ¯ğŸ¯ğŸ¯               | Desacopla lÃ³gica del CLI. Permite que el agente Copilot consuma LibrarAI via HTTP en lugar de shell. MÃ¡s limpio, mejor manejo de errores, tipado de respuestas. |   â­â­â­    | Nuevo `src/api/`                    |  â­ï¸ Omitido (CLI)   |
| 12  | **CachÃ© SemÃ¡ntica (GPTCache)**         | ğŸ¯ğŸ¯ğŸ¯               | Si una query es semÃ¡nticamente equivalente a una anterior (no idÃ©ntica), devuelve respuesta cacheada. Reduce costes LLM dramÃ¡ticamente.                         |   â­â­â­    | Nuevo `semantic_cache.py`           |    âœ… Completado    |
| 13  | **IndexaciÃ³n Paralela**                | ğŸ¯ğŸ¯                 | Actualmente secuencial. Paralelizar embeddings acelera 3-5x. Importante para reindexaciones tras aÃ±adir libros.                                                 |   â­â­â­    | `indexer.py`                        |    âœ… Completado    |
| 14  | **CompresiÃ³n de Contexto (LLMLingua)** | ğŸ¯ğŸ¯                 | Comprime chunks antes de enviar al LLM. Reduce tokens 50-70%. Permite mÃ¡s contexto en el mismo presupuesto de tokens.                                           |   â­â­â­    | `prompt_builder.py`                 |    âœ… Completado    |
| 15  | **Embeddings Locales con GPU**         | ğŸ¯ğŸ¯                 | Elimina dependencia de API OpenAI para embeddings. BGE-M3 o E5-mistral-7b dan calidad comparable. Reduce costes a cero.                                         |   â­â­â­    | `indexer.py`, `vector_retriever.py` | â­ï¸ Omitido (OpenAI) |

---

## ğŸŸ¢ TIER 4: Mejoras de Robustez y Mantenibilidad

|  #  | LÃ­nea de Trabajo                         | Impacto en PrecisiÃ³n | Mejora que Ofrece                                                                                      | Complejidad | Archivos Afectados                 |    Estado     |
| :-: | :--------------------------------------- | :------------------- | :----------------------------------------------------------------------------------------------------- | :---------: | :--------------------------------- | :-----------: |
| 16  | **Tests Unitarios y de IntegraciÃ³n**     | ğŸ¯ğŸ¯                 | No hay tests. Impide refactoring seguro. Necesario para evoluciÃ³n sostenible.                          |   â­â­â­    | Nuevo `tests/`                     | âœ… Completado |
| 17  | **DockerizaciÃ³n Completa**               | ğŸ¯ğŸ¯                 | `docker-compose` con RAG + Qdrant. Reproducibilidad total.                                             |    â­â­     | `docker-compose.yml`, `Dockerfile` |               |
| 18  | **Logging Estructurado (OpenTelemetry)** | ğŸ¯                   | Tracing para debugging. Ãštil cuando el agente reporta respuestas pobres y hay que diagnosticar.        |    â­â­     | Todos los mÃ³dulos                  |               |
| 19  | **Ampliar Whitelist del Sandbox**        | ğŸ¯                   | Faltan: `networkx`, `scikit-learn`, `pennylane`, `cirq`. Limita cÃ¡lculos que el agente puede ejecutar. |     â­      | `sandbox.py`                       |               |
| 20  | **ValidaciÃ³n de CÃ³digo con AST**         | ğŸ¯                   | AnÃ¡lisis estÃ¡tico del cÃ³digo generado. Detecta bucles infinitos potenciales antes de ejecutar.         |    â­â­     | `sandbox.py`                       |               |

---

## ğŸ”µ TIER 5: Experimental / Largo Plazo

|  #  | LÃ­nea de Trabajo                         | Impacto en PrecisiÃ³n | Mejora que Ofrece                                                                                                                                             | Complejidad | Archivos Afectados          |
| :-: | :--------------------------------------- | :------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------ | :---------: | :-------------------------- |
| 21  | **IndexaciÃ³n "Math-Aware"**              | ğŸ¯ğŸ¯ğŸ¯ğŸ¯             | Parsear fÃ³rmulas LaTeX a representaciÃ³n semÃ¡ntica. Buscar "ecuaciÃ³n de onda" encuentra $\Psi(x,t)$. Muy difÃ­cil pero alto impacto para biblioteca matemÃ¡tica. | â­â­â­â­â­  | `parser.py`, `chunker.py`   |
| 22  | **GraphRAG con ExtracciÃ³n LLM Completa** | ğŸ¯ğŸ¯ğŸ¯               | Actualmente solo 10% de chunks usan LLM. Expandir mejora el grafo significativamente pero es costoso.                                                         |  â­â­â­â­   | `graph_retriever.py`        |
| 23  | **Agente con Tool Use**                  | ğŸ¯ğŸ¯ğŸ¯               | LLM decide cuÃ¡ndo buscar mÃ¡s, ejecutar cÃ³digo, o pedir clarificaciÃ³n. Arquitectura agentic completa.                                                          | â­â­â­â­â­  | `agents/`, `ask_library.py` |
| 24  | **Fine-tuning de Embeddings**            | ğŸ¯ğŸ¯ğŸ¯ğŸ¯             | Entrenar adaptador sobre text-embedding-3-large con pares query-chunk del dominio. +10-20% precision pero requiere dataset de evaluaciÃ³n.                     | â­â­â­â­â­  | Nuevo pipeline de training  |
| 25  | **MigraciÃ³n de NetworkX a Neo4j**        | ğŸ¯ğŸ¯                 | NetworkX corre en memoria. Neo4j escala mejor y permite consultas Cypher complejas. Solo necesario si el grafo crece mucho.                                   |  â­â­â­â­   | `graph_retriever.py`        |

---

## ğŸ“Š Matriz de PriorizaciÃ³n (Impacto vs Complejidad)

```
                    COMPLEJIDAD
                    Baja â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Alta
                    â”‚
     Alto â”‚   [7] Pesos DinÃ¡micos    [1] Re-ranking
          â”‚   [5] Qdrant Docker      [2] RAGAS
          â”‚                          [3] CachÃ© Embeddings
          â”‚                          [4] Filtrado Metadata
   I      â”‚                          [6] HyDE
   M      â”‚
   P      â”‚
   A      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   C      â”‚
   T      â”‚   [17] Docker Compose    [9] Memoria Conv.
   O      â”‚   [19] Whitelist         [10] Chunking Sem.
          â”‚                          [11] API REST
     Bajo â”‚   [18] Logging           [21] Math-Aware
          â”‚                          [24] Fine-tuning
          â”‚
```

**Quick Wins (Alto impacto, Baja complejidad):**

- #5 Qdrant Docker
- #7 Pesos DinÃ¡micos

**Inversiones EstratÃ©gicas (Alto impacto, Alta complejidad):**

- #1 Re-ranking
- #2 RAGAS
- #6 HyDE

---

## ğŸš€ Plan de ImplementaciÃ³n Sugerido

### Sprint 1: Fundamentos (1-2 semanas)

- [ ] #5 Migrar Qdrant a Docker
- [ ] #3 Implementar cachÃ© de embeddings
- [ ] #7 Pesos dinÃ¡micos en fusion segÃºn query type
- [ ] #19 Ampliar whitelist del sandbox

### Sprint 2: PrecisiÃ³n de Retrieval (2-3 semanas)

- [ ] #1 Re-ranking con cross-encoder
- [ ] #4 Filtrado por categorÃ­a/metadata
- [ ] #8 Ampliar ontologÃ­a para matemÃ¡ticas

### Sprint 3: EvaluaciÃ³n y Calidad (2-3 semanas)

- [ ] #2 Pipeline RAGAS
- [ ] #6 HyDE para expansiÃ³n de queries
- [ ] #16 Tests bÃ¡sicos

### Sprint 4: IntegraciÃ³n ProgramÃ¡tica (2-3 semanas)

- [ ] #11 API REST con FastAPI
- [ ] #9 Memoria conversacional
- [ ] #17 Docker Compose completo

### Backlog Futuro

- #10 Chunking semÃ¡ntico
- #12 CachÃ© semÃ¡ntica
- #21 IndexaciÃ³n math-aware
- #23 Arquitectura agentic

---

## ğŸ’¡ Notas para Uso por Agente Copilot

### PatrÃ³n de Uso Recomendado

```python
# El agente puede invocar asÃ­:
response = ask_library(
    query="Demuestra el teorema de Noether",
    filters={"categoria": "mecanica_cuantica"},
    top_k=8,
    critic=True
)

# Y usar la respuesta para redactar:
apunte = f"""
## Teorema de Noether

{response.content}

### Fuentes
{format_citations(response.sources)}
"""
```

### IntegraciÃ³n con Copilot

Una vez implementada la **API REST (#11)**, el agente puede:

1. **Consultar**: `POST /query` con filtros
2. **Verificar citas**: Respuesta incluye `sources` con `chunk_id` y `header_path`
3. **Ejecutar cÃ³digo**: `POST /execute` para cÃ¡lculos
4. **Contexto conversacional**: `session_id` para continuidad

### Prioridades desde Perspectiva del Agente

1. **PrecisiÃ³n** â†’ Re-ranking + RAGAS + Filtros
2. **Eficiencia** â†’ CachÃ© + Qdrant Docker
3. **IntegraciÃ³n** â†’ API REST
4. **Contexto** â†’ Memoria conversacional

---

_Roadmap consolidado a partir de anÃ¡lisis de Claude Opus 4.5 y Gemini, adaptado para consumo por agente GitHub Copilot._
