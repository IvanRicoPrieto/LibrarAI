# ğŸ“š LibrarAI - DocumentaciÃ³n TÃ©cnica del Sistema

**VersiÃ³n:** 2.0
**Ãšltima actualizaciÃ³n:** 7 de enero de 2026
**Estado:** âœ… Sistema completamente implementado y operativo

---

## ğŸ“‹ Ãndice

1. [Resumen Ejecutivo](#1-resumen-ejecutivo)
2. [CaracterÃ­sticas Implementadas](#2-caracterÃ­sticas-implementadas)
3. [Arquitectura del Sistema](#3-arquitectura-del-sistema)
4. [Stack TecnolÃ³gico](#4-stack-tecnolÃ³gico)
5. [Componentes del Sistema](#5-componentes-del-sistema)
6. [GuÃ­a de Uso](#6-guÃ­a-de-uso)
7. [ConfiguraciÃ³n](#7-configuraciÃ³n)
8. [Despliegue con Docker](#8-despliegue-con-docker)
9. [Testing](#9-testing)
10. [MÃ©tricas y Observabilidad](#10-mÃ©tricas-y-observabilidad)
11. [Estructura del Proyecto](#11-estructura-del-proyecto)
12. [EstimaciÃ³n de Costes](#12-estimaciÃ³n-de-costes)
13. [Roadmap y Trabajo Futuro](#13-roadmap-y-trabajo-futuro)

---

## 1. Resumen Ejecutivo

**LibrarAI** es un sistema RAG (Retrieval-Augmented Generation) agÃ©ntico diseÃ±ado para consultar bibliotecas tÃ©cnicas de FÃ­sica, MatemÃ¡ticas y ComputaciÃ³n CuÃ¡ntica. El sistema permite:

- ğŸ” **Recuperar informaciÃ³n** relevante de documentos Markdown usando bÃºsqueda hÃ­brida
- ğŸ“ **Generar respuestas** fundamentadas con citas precisas a las fuentes
- ğŸ¤– **IntegraciÃ³n con agentes** como Claude Code para redacciÃ³n asistida
- ğŸ’° **OptimizaciÃ³n de costes** mediante mÃºltiples capas de cachÃ©

### Estado de ImplementaciÃ³n

| Componente             | Estado | DescripciÃ³n                                |
| ---------------------- | :----: | ------------------------------------------ |
| BÃºsqueda HÃ­brida       |   âœ…   | Vector + BM25 + GraphRAG con fusiÃ³n RRF    |
| Re-ranking             |   âœ…   | Cross-Encoder con 4 presets de calidad     |
| HyDE                   |   âœ…   | Query expansion con documentos hipotÃ©ticos |
| EvaluaciÃ³n RAGAS       |   âœ…   | Pipeline completo con 6 mÃ©tricas           |
| Cache Embeddings       |   âœ…   | Reduce costes 70-90%                       |
| Cache SemÃ¡ntico        |   âœ…   | Respuestas cacheadas por similitud         |
| CompresiÃ³n Contexto    |   âœ…   | Reduce tokens 30-60%                       |
| Memoria Conversacional |   âœ…   | Sesiones multi-turno                       |
| Filtrado Metadata      |   âœ…   | Por categorÃ­a/dominio                      |
| Chunking SemÃ¡ntico     |   âœ…   | Detecta teoremas, definiciones, etc.       |
| Code Sandbox           |   âœ…   | EjecuciÃ³n segura con validaciÃ³n AST        |
| DockerizaciÃ³n          |   âœ…   | docker-compose con Qdrant + App            |
| Logging Estructurado   |   âœ…   | structlog con tracing                      |
| Tests                  |   âœ…   | 66 tests pasando                           |

---

## 2. CaracterÃ­sticas Implementadas

### 2.1 RecuperaciÃ³n de InformaciÃ³n

| CaracterÃ­stica         | Mejora  | DescripciÃ³n                                            |
| ---------------------- | :-----: | ------------------------------------------------------ |
| **BÃºsqueda Vectorial** |  Base   | Embeddings OpenAI text-embedding-3-large (3072 dims)   |
| **BÃºsqueda LÃ©xica**    |  Base   | BM25 para coincidencias exactas                        |
| **GraphRAG**           | +10-15% | Grafo de conocimiento con 18 entidades y 19 relaciones |
| **FusiÃ³n RRF**         | +5-10%  | Reciprocal Rank Fusion con k=60                        |
| **Re-ranking**         | +15-25% | Cross-Encoder ms-marco-MiniLM                          |
| **HyDE**               | +10-20% | Hypothetical Document Embeddings                       |
| **Pesos DinÃ¡micos**    | +5-10%  | Adapta pesos segÃºn tipo de query                       |
| **Filtrado Metadata**  |    -    | Filtra por categorÃ­a/dominio                           |

### 2.2 OptimizaciÃ³n de Costes

| CaracterÃ­stica          |  Ahorro  | DescripciÃ³n                                  |
| ----------------------- | :------: | -------------------------------------------- |
| **Cache Embeddings**    |  70-90%  | LRU cache con persistencia en disco          |
| **Cache SemÃ¡ntico**     | 100%/hit | Reutiliza respuestas similares (umbral 0.92) |
| **CompresiÃ³n Contexto** |  30-60%  | 3 niveles: light/medium/aggressive           |
| **IndexaciÃ³n Paralela** |   3-5x   | Embeddings en paralelo (10 workers)          |

### 2.3 Calidad y VerificaciÃ³n

| CaracterÃ­stica          | DescripciÃ³n                                                                      |
| ----------------------- | -------------------------------------------------------------------------------- |
| **EvaluaciÃ³n RAGAS**    | 6 mÃ©tricas: faithfulness, relevancy, precision, recall, harmfulness, correctness |
| **Critic**              | ValidaciÃ³n de citas antes de entregar respuesta                                  |
| **Chunking SemÃ¡ntico**  | Preserva definiciones, teoremas, demostraciones                                  |
| **OntologÃ­a Extendida** | 18 tipos de entidades, 19 relaciones matemÃ¡ticas/cuÃ¡nticas                       |

### 2.4 EjecuciÃ³n de CÃ³digo

| CaracterÃ­stica         | DescripciÃ³n                                                                |
| ---------------------- | -------------------------------------------------------------------------- |
| **Sandbox Seguro**     | Subprocess aislado o Docker container                                      |
| **ValidaciÃ³n AST**     | Detecta bucles infinitos, recursiÃ³n, cÃ³digo peligroso                      |
| **Whitelist Ampliada** | numpy, scipy, sympy, matplotlib, qutip, pennylane, cirq, sklearn, networkx |
| **Captura de Figuras** | GrÃ¡ficas matplotlib embebidas en respuesta                                 |

### 2.5 Robustez

| CaracterÃ­stica             | DescripciÃ³n                                  |
| -------------------------- | -------------------------------------------- |
| **DockerizaciÃ³n**          | docker-compose con Qdrant, App y Sandbox     |
| **Logging Estructurado**   | structlog con JSON/console, trace context    |
| **Tests**                  | 66 tests unitarios + integraciÃ³n             |
| **Memoria Conversacional** | Sesiones persistentes, detecciÃ³n de followup |

---

## 3. Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           USUARIO                                   â”‚
â”‚                      (Terminal / VS Code / Agente)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CAPA DE INTERFAZ                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ CLI Parser   â”‚  â”‚ Session      â”‚  â”‚ Output       â”‚               â”‚
â”‚  â”‚ (click)      â”‚  â”‚ Manager      â”‚  â”‚ Formatter    â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CAPA DE CACHÃ‰                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚  â”‚ Semantic     â”‚  â”‚ Embedding    â”‚  â† 100% ahorro si hit           â”‚
â”‚  â”‚ Cache        â”‚  â”‚ Cache        â”‚  â† 70-90% ahorro embeddings     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CAPA AGÃ‰NTICA                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Router       â”‚  â”‚ Planner      â”‚  â”‚ Critic       â”‚               â”‚
â”‚  â”‚ (GPT-4.1-m)  â”‚  â”‚ (Deep Res.)  â”‚  â”‚ (Verify)     â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CAPA DE RECUPERACIÃ“N                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Vector       â”‚  â”‚ BM25         â”‚  â”‚ Graph        â”‚               â”‚
â”‚  â”‚ Retriever    â”‚  â”‚ Retriever    â”‚  â”‚ Retriever    â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚         â”‚                 â”‚                 â”‚                       â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                           â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ HyDE         â”‚  â”‚ RRF Fusion   â”‚  â”‚ Re-Ranker    â”‚               â”‚
â”‚  â”‚ (opcional)   â”‚  â”‚ + Auto-Merge â”‚  â”‚ (opcional)   â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CAPA DE GENERACIÃ“N                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Context      â”‚  â”‚ LLM          â”‚  â”‚ Citation     â”‚               â”‚
â”‚  â”‚ Compressor   â”‚  â”‚ (Claude)     â”‚  â”‚ Injector     â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA DE ALMACENAMIENTO                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Qdrant       â”‚  â”‚ BM25 Index   â”‚  â”‚ Knowledge    â”‚               â”‚
â”‚  â”‚ (Docker)     â”‚  â”‚ (Pickle)     â”‚  â”‚ Graph (NX)   â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Stack TecnolÃ³gico

### 4.1 Componentes Principales

| Componente    | TecnologÃ­a            | VersiÃ³n | JustificaciÃ³n                          |
| ------------- | --------------------- | ------- | -------------------------------------- |
| Framework RAG | LlamaIndex            | 0.10+   | Chunking jerÃ¡rquico, citations nativas |
| Vector DB     | Qdrant                | latest  | Escalable, filtrado metadata, Docker   |
| Ãndice LÃ©xico | rank_bm25             | 0.2.2   | Ligero, sin servidor                   |
| Grafos        | NetworkX              | 3.2+    | En memoria, suficiente para ~500 docs  |
| Re-ranker     | sentence-transformers | 2.2+    | ms-marco-MiniLM local                  |
| EvaluaciÃ³n    | RAGAS                 | custom  | LLM-as-judge                           |

### 4.2 Modelos de IA

| Uso             | Modelo                 | Provider  | Precio             |
| --------------- | ---------------------- | --------- | ------------------ |
| **GeneraciÃ³n**  | Claude Sonnet 4.5      | Anthropic | $3/$15 per 1M      |
| **Alternativa** | GPT-4.1                | OpenAI    | $2.50/$10 per 1M   |
| **Ruteo**       | GPT-4.1-mini           | OpenAI    | $0.15/$0.60 per 1M |
| **Embeddings**  | text-embedding-3-large | OpenAI    | $0.13 per 1M       |

### 4.3 Infraestructura

| Componente   | TecnologÃ­a              | DescripciÃ³n                     |
| ------------ | ----------------------- | ------------------------------- |
| Contenedores | Docker + Compose        | Qdrant, App, Sandbox aislado    |
| Logging      | structlog               | JSON/console, trace correlation |
| Testing      | pytest + pytest-asyncio | 66 tests, fixtures compartidos  |
| Cache        | SQLite + LRU            | Persistente en disco            |

---

## 5. Componentes del Sistema

### 5.1 Ingestion (`src/ingestion/`)

| Archivo      | FunciÃ³n                                            |
| ------------ | -------------------------------------------------- |
| `parser.py`  | Parser Markdown con extracciÃ³n de header_path      |
| `chunker.py` | Chunking jerÃ¡rquico (Macro/Meso/Micro) + semÃ¡ntico |
| `indexer.py` | IndexaciÃ³n paralela (10 workers), incremental      |

**Chunking JerÃ¡rquico:**

| Nivel | TamaÃ±o      | Contenido              | Uso             |
| ----- | ----------- | ---------------------- | --------------- |
| Macro | 2048 tokens | SecciÃ³n completa       | Contexto amplio |
| Meso  | 512 tokens  | PÃ¡rrafos relacionados  | Balance         |
| Micro | 200 tokens  | Definiciones, teoremas | Alta precisiÃ³n  |

**Chunking SemÃ¡ntico:** Detecta y preserva bloques atÃ³micos:

- Definiciones, Teoremas, Lemas, Corolarios
- Demostraciones, Ejemplos, Algoritmos
- Protocolos, CÃ³digo, Ecuaciones

### 5.2 Retrieval (`src/retrieval/`)

| Archivo               | FunciÃ³n                                   |
| --------------------- | ----------------------------------------- |
| `vector_retriever.py` | BÃºsqueda semÃ¡ntica en Qdrant              |
| `bm25_retriever.py`   | BÃºsqueda lÃ©xica exacta                    |
| `graph_retriever.py`  | Traversal del grafo de conocimiento       |
| `fusion.py`           | RRF fusion + Auto-merge + Pesos dinÃ¡micos |
| `reranker.py`         | Cross-Encoder re-ranking (4 presets)      |
| `hyde.py`             | HyDE query expansion                      |
| `cache.py`            | Cache de embeddings con LRU               |
| `semantic_cache.py`   | Cache semÃ¡ntico de respuestas             |
| `compressor.py`       | CompresiÃ³n de contexto (3 niveles)        |

**Presets de Re-ranking:**

| Preset      | top_k | Modelo               | Latencia |
| ----------- | ----- | -------------------- | -------- |
| fast        | 50    | ms-marco-MiniLM-L-4  | ~100ms   |
| balanced    | 100   | ms-marco-MiniLM-L-6  | ~200ms   |
| quality     | 150   | ms-marco-MiniLM-L-12 | ~500ms   |
| max_quality | 200   | cross-encoder/stsb   | ~1s      |

**Niveles de CompresiÃ³n:**

| Nivel      | ReducciÃ³n | Caso de uso       |
| ---------- | --------- | ----------------- |
| light      | ~20%      | Preserva detalles |
| medium     | ~40%      | Balance           |
| aggressive | ~60%      | SÃ­ntesis amplia   |

### 5.3 Generation (`src/generation/`)

| Archivo                | FunciÃ³n                                   |
| ---------------------- | ----------------------------------------- |
| `prompt_builder.py`    | Construye prompts con contexto comprimido |
| `synthesizer.py`       | Llamada a LLM (Claude/GPT-4.1)            |
| `citation_injector.py` | Inyecta citas `[n]` en respuesta          |

### 5.4 Agents (`src/agents/`)

| Archivo              | FunciÃ³n                                     |
| -------------------- | ------------------------------------------- |
| `router.py`          | Clasifica query y asigna pesos dinÃ¡micos    |
| `planner.py`         | Deep Research: descompone queries complejas |
| `critic.py`          | Verifica fidelidad de citas                 |
| `session_manager.py` | Memoria conversacional multi-turno          |

### 5.5 Execution (`src/execution/`)

| Archivo      | FunciÃ³n                           |
| ------------ | --------------------------------- |
| `sandbox.py` | EjecuciÃ³n segura de cÃ³digo Python |

**CaracterÃ­sticas del Sandbox:**

- Whitelist de 34 mÃ³dulos (numpy, scipy, sympy, matplotlib, qutip, pennylane, cirq, sklearn, networkx...)
- ValidaciÃ³n AST: detecta bucles infinitos, recursiÃ³n, atributos peligrosos
- Timeout configurable (default 30s)
- Modo Docker para mÃ¡ximo aislamiento

### 5.6 Evaluation (`src/evaluation/`)

| Archivo              | FunciÃ³n                      |
| -------------------- | ---------------------------- |
| `ragas_evaluator.py` | Pipeline de evaluaciÃ³n RAGAS |
| `metrics.py`         | 6 mÃ©tricas de calidad        |
| `test_suite.py`      | Suite de benchmark           |

**MÃ©tricas RAGAS:**

| MÃ©trica            | DescripciÃ³n                         |
| ------------------ | ----------------------------------- |
| Faithfulness       | Â¿Respuesta fiel al contexto?        |
| Answer Relevancy   | Â¿Respuesta relevante a la pregunta? |
| Context Precision  | Â¿Contexto recuperado es preciso?    |
| Context Recall     | Â¿Se recuperÃ³ todo lo relevante?     |
| Answer Correctness | Â¿Respuesta factualmente correcta?   |
| Harmfulness        | Â¿Respuesta potencialmente daÃ±ina?   |

### 5.7 Utils (`src/utils/`)

| Archivo             | FunciÃ³n                            |
| ------------------- | ---------------------------------- |
| `logging_config.py` | Logging estructurado con structlog |
| `cost_tracker.py`   | Seguimiento de costes por query    |

### 5.8 Agent API (`src/api/`)

**Nueva API estructurada optimizada para agentes de IA.**

| Archivo              | FunciÃ³n                              |
| -------------------- | ------------------------------------ |
| `agent_interface.py` | 5 modos de operaciÃ³n con output JSON |
| `__init__.py`        | Exports pÃºblicos                     |

**Modos de OperaciÃ³n:**

| Modo     | FunciÃ³n                               | Retorna                         |
| -------- | ------------------------------------- | ------------------------------- |
| EXPLORE  | Descubrir contenido disponible        | Ãrbol de contenido, sugerencias |
| RETRIEVE | Obtener contenido exhaustivo          | Lista completa de chunks        |
| QUERY    | Responder preguntas con citas         | Respuesta + claims + citations  |
| VERIFY   | Verificar afirmaciones contra fuentes | Status + evidencia + confianza  |
| CITE     | Generar citas formateadas             | Citas en APA/IEEE/Chicago/MD    |

**CLI asociado:** `python -m src.cli.librari <comando>`

Ver [CLAUDE.md](../CLAUDE.md) para guÃ­a completa de uso.

---

## 6. GuÃ­a de Uso

### 6.1 Comandos BÃ¡sicos

```bash
# Activar entorno
cd "/home/ivan/ComputaciÃ³n CuÃ¡ntica/LibrarAI"
source .venv/bin/activate

# Consulta simple
python -m src.cli.ask_library "Â¿QuÃ© es el algoritmo de Shor?"

# Consulta con mÃ¡xima calidad
python -m src.cli.ask_library "Explica BB84" --rerank --hyde --critic

# Deep Research para queries complejas
python -m src.cli.ask_library "Compara BB84 con E91" --deep

# Con compresiÃ³n para incluir mÃ¡s contexto
python -m src.cli.ask_library "Resumen de protocolos QKD" --compress --top-k 20

# Modo interactivo con memoria
python -m src.cli.ask_library --interactive

# Solo ver fuentes (sin generar respuesta)
python -m src.cli.ask_library "BB84" --sources

# Filtrar por categorÃ­a
python -m src.cli.ask_library "TeorÃ­a de grupos" --filter categoria:algebra

# Ejecutar cÃ³digo de la respuesta
python -m src.cli.ask_library "Calcula entropÃ­a de von Neumann" --exec
```

### 6.2 ParÃ¡metros Completos

| ParÃ¡metro             | Tipo   | Default  | DescripciÃ³n                          |
| --------------------- | ------ | -------- | ------------------------------------ |
| `--model`             | choice | claude   | claude, gpt-4.1, gpt-4.1-mini, local |
| `--top-k`             | int    | 10       | Documentos a recuperar               |
| `--deep`              | flag   | false    | Deep Research mode                   |
| `--rerank`            | flag   | false    | Activar re-ranking                   |
| `--rerank-preset`     | choice | balanced | fast, balanced, quality, max_quality |
| `--hyde`              | flag   | false    | HyDE query expansion                 |
| `--compress`          | flag   | false    | CompresiÃ³n de contexto               |
| `--compress-level`    | choice | medium   | light, medium, aggressive            |
| `--critic`            | flag   | false    | ValidaciÃ³n de citas                  |
| `--exec`              | flag   | false    | Permitir ejecuciÃ³n de cÃ³digo         |
| `--filter`            | string | -        | Filtrar metadata (KEY:VALUE)         |
| `--no-cache`          | flag   | false    | Deshabilitar cache embeddings        |
| `--no-semantic-cache` | flag   | false    | Deshabilitar cache semÃ¡ntico         |
| `--json`              | flag   | false    | Salida JSON                          |
| `--verbose`           | flag   | false    | Logging detallado                    |

### 6.3 EvaluaciÃ³n

```bash
# Evaluar query individual
python -m src.cli.evaluate --query "Â¿QuÃ© es el entrelazamiento?"

# Benchmark completo
python -m src.cli.evaluate --suite default

# Comparar con baseline
python -m src.cli.evaluate --suite default --baseline benchmark_results/baseline.json
```

### 6.4 IndexaciÃ³n

```bash
# Re-indexar todo
python -m src.cli.ingest_library

# Solo documentos nuevos/modificados
python -m src.cli.ingest_library --update

# Ver quÃ© se indexarÃ­a
python -m src.cli.ingest_library --dry-run
```

---

## 7. ConfiguraciÃ³n

### 7.1 Archivo Principal (`config/settings.yaml`)

```yaml
# Embeddings
embedding:
  provider: "openai"
  model: "text-embedding-3-large"
  dimensions: 3072
  batch_size: 100

# Chunking
chunking:
  micro_size: 200
  meso_size: 512
  macro_size: 2048
  overlap: 50

# Retrieval
retrieval:
  vector_top_k: 30
  bm25_top_k: 30
  rrf_k: 60
  fusion_top_k: 10
  final_top_k: 5
  auto_merge_threshold: 0.5
  min_similarity_threshold: 0.65

# Generation
generation:
  provider: "anthropic"
  model: "claude-sonnet-4-5-20250929"
  temperature: 0.3
  max_tokens: 2000

# Routing
routing:
  provider: "openai"
  model: "gpt-4.1-mini"
  temperature: 0.1
```

### 7.2 Variables de Entorno (`.env`)

```bash
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
QDRANT_URL=http://localhost:6333  # Si usas Docker
```

### 7.3 OntologÃ­a (`config/ontology.yaml`)

18 tipos de entidades organizados en categorÃ­as:

- **ComputaciÃ³n CuÃ¡ntica:** Algoritmo, Protocolo, Gate, Hardware
- **FÃ­sica:** Concepto, Teorema, Autor, Documento
- **MatemÃ¡ticas:** EstructuraAlgebraica, GrupoEspecifico, EspacioVectorial, Operador
- **TopologÃ­a:** EspacioTopologico, InvarianteTopologico, ConceptoAnalisis, TeoremaMath
- **InformaciÃ³n:** MedidaInformacion, Canal

19 tipos de relaciones:

- ComputaciÃ³n: MEJORA, DEPENDE_DE, USA, IMPLEMENTA, CITA, DEFINE, DEMUESTRA, PROPONE, ES_CASO_DE, EQUIVALE_A
- MatemÃ¡ticas: ACTUA_SOBRE, SUBESPACIO_DE, SUBGRUPO_DE, GENERA, PRESERVA, SE_DESCOMPONE_EN, CARACTERIZA, SATISFACE, REPRESENTA

---

## 8. Despliegue con Docker

### 8.1 Desarrollo (Solo Qdrant)

```bash
# Iniciar Qdrant
docker compose up -d qdrant

# Verificar
curl http://localhost:6333/readiness

# Dashboard: http://localhost:6333/dashboard
```

### 8.2 ProducciÃ³n (Stack Completo)

```bash
# Iniciar todo
docker compose --profile production up -d

# Ver logs
docker compose logs -f librar_ai

# Detener
docker compose down
```

### 8.3 Servicios Disponibles

| Servicio    | Puerto | DescripciÃ³n               |
| ----------- | ------ | ------------------------- |
| Qdrant REST | 6333   | API vectorial + Dashboard |
| Qdrant gRPC | 6334   | API de alto rendimiento   |
| LibrarAI    | 8000   | App (profile production)  |

### 8.4 VolÃºmenes

```yaml
volumes:
  qdrant_data: # Datos vectoriales persistentes
  sandbox_code: # CÃ³digo para sandbox aislado
```

---

## 9. Testing

### 9.1 Ejecutar Tests

```bash
# Todos los tests
pytest tests/ -v

# Por componente
pytest tests/test_compressor.py -v
pytest tests/test_fusion.py -v
pytest tests/test_cache.py -v
pytest tests/test_chunker.py -v

# Tests de integraciÃ³n
pytest tests/test_integration.py -v

# Con cobertura
pytest tests/ --cov=src --cov-report=html

# Excluir tests de integraciÃ³n
pytest tests/ -v -m "not integration"
```

### 9.2 Estructura de Tests

| Archivo             | Tests  | Cobertura               |
| ------------------- | :----: | ----------------------- |
| test_compressor.py  |   21   | CompresiÃ³n de contexto  |
| test_fusion.py      |   16   | FusiÃ³n RRF, re-ranking  |
| test_cache.py       |   16   | Cache embeddings        |
| test_chunker.py     |   11   | Chunking jerÃ¡rquico     |
| test_integration.py |   10   | Pipeline end-to-end     |
| **Total**           | **74** | (66 passing, 8 skipped) |

---

## 10. MÃ©tricas y Observabilidad

### 10.1 Logging Estructurado

```python
from src.utils.logging_config import get_logger, trace_context

logger = get_logger(__name__)

with trace_context(query="Â¿QuÃ© es BB84?", session_id="abc123"):
    logger.info("processing_query", top_k=5, filters={"domain": "qkd"})
```

**Formato JSON (producciÃ³n):**

```json
{
  "timestamp": "2026-01-07T14:35:22Z",
  "level": "info",
  "event": "query_processed",
  "trace_id": "abc12345",
  "service": "librar_ai",
  "total_time_ms": 2800,
  "chunks_used": 5,
  "tokens_total": 3500
}
```

### 10.2 MÃ©tricas RAG

```python
from src.utils.logging_config import RAGMetrics

metrics = RAGMetrics(trace_id="abc123", query="...")
metrics.embedding_time_ms = 50
metrics.vector_search_time_ms = 120
metrics.generation_time_ms = 2000
metrics.embedding_cache_hit = True
metrics.log()
```

### 10.3 Cost Tracking

Archivo: `logs/cost_tracking.csv`

```csv
timestamp,query,model,tokens_in,tokens_out,cost_usd
2026-01-07T14:35:22,Â¿QuÃ© es Shor?,claude-sonnet-4-5,3200,480,0.018
```

---

## 11. Estructura del Proyecto

```
LibrarAI/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.yaml          # ConfiguraciÃ³n principal
â”‚   â””â”€â”€ ontology.yaml          # OntologÃ­a del dominio
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ books/                 # Libros por categorÃ­a
â”‚   â””â”€â”€ papers/                # Papers por tema
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ CLI_AGENT_MANUAL.md    # Manual para agentes IA
â”‚   â””â”€â”€ ADDING_DOCUMENTS.md    # GuÃ­a para aÃ±adir docs
â”œâ”€â”€ indices/
â”‚   â”œâ”€â”€ qdrant/                # Base de datos vectorial
â”‚   â”œâ”€â”€ bm25_index.pkl         # Ãndice BM25
â”‚   â”œâ”€â”€ chunks.pkl             # AlmacÃ©n de chunks
â”‚   â””â”€â”€ manifest.json          # Tracking de documentos
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ cost_tracking.csv      # Seguimiento de costes
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/               # GrÃ¡ficas generadas
â”‚   â””â”€â”€ sessions/              # Sesiones persistidas
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                # Router, Planner, Critic
â”‚   â”œâ”€â”€ cli/                   # ask_library, ingest_library
â”‚   â”œâ”€â”€ evaluation/            # RAGAS, mÃ©tricas
â”‚   â”œâ”€â”€ execution/             # Sandbox de cÃ³digo
â”‚   â”œâ”€â”€ generation/            # Prompt, Synthesizer
â”‚   â”œâ”€â”€ ingestion/             # Parser, Chunker, Indexer
â”‚   â”œâ”€â”€ retrieval/             # Vector, BM25, Graph, Fusion
â”‚   â””â”€â”€ utils/                 # Logging, Cost tracking
â”œâ”€â”€ tests/                     # Suite de tests pytest
â”œâ”€â”€ future_work/
â”‚   â””â”€â”€ ROADMAP_FINAL.md       # Trabajo futuro
â”œâ”€â”€ docker-compose.yml         # Stack Docker
â”œâ”€â”€ Dockerfile                 # Imagen de producciÃ³n
â”œâ”€â”€ pytest.ini                 # ConfiguraciÃ³n tests
â”œâ”€â”€ requirements.txt           # Dependencias Python
â””â”€â”€ README.md                  # GuÃ­a rÃ¡pida
```

---

## 12. EstimaciÃ³n de Costes

### 12.1 Setup Inicial (Una vez)

| Concepto                             | CÃ¡lculo          |      Coste |
| ------------------------------------ | ---------------- | ---------: | --- |
| Embeddings biblioteca (~375k tokens) | 375k Ã— $0.13/1M  |  **$0.05** |     |
| ExtracciÃ³n grafo                     | ~500k Ã— $0.15/1M |  **$0.08** |     |
| **TOTAL**                            |                  | **~$0.15** |

### 12.2 Coste por Uso

| Tipo Query    |  %  | Tokens In/Out |  Coste |
| ------------- | :-: | ------------- | -----: |
| Simple        | 60% | 3k/500        | $0.016 |
| Compleja      | 30% | 15k/1k        | $0.060 |
| Deep Research | 10% | 25k/1.5k      | $0.098 |

**Promedio: ~$0.04/query**

### 12.3 Ahorro con CachÃ©

| Escenario       | Sin CachÃ© | Con CachÃ© | Ahorro |
| --------------- | --------: | --------: | -----: | --- |
| 100 queries     |     $3.75 |     $1.50 |    60% |     |
| 500 queries/mes |    $18.75 |     $7.50 |    60% |     |

---

## 13. Roadmap y Trabajo Futuro

### 13.1 Completado (TIER 1-4)

âœ… Re-ranking con Cross-Encoder
âœ… Pipeline RAGAS
âœ… Cache de Embeddings
âœ… Filtrado por Metadata
âœ… Qdrant en Docker
âœ… HyDE Query Expansion
âœ… Pesos DinÃ¡micos
âœ… OntologÃ­a Extendida
âœ… Memoria Conversacional
âœ… Chunking SemÃ¡ntico
âœ… Cache SemÃ¡ntico
âœ… IndexaciÃ³n Paralela
âœ… CompresiÃ³n de Contexto
âœ… Tests Unitarios
âœ… DockerizaciÃ³n Completa
âœ… Logging Estructurado
âœ… Whitelist Sandbox Ampliada
âœ… ValidaciÃ³n AST

### 13.2 Trabajo Futuro (TIER 5)

|  #  | Mejora                 | Complejidad | DescripciÃ³n                   |
| :-: | ---------------------- | :---------: | ----------------------------- |
| 21  | IndexaciÃ³n Math-Aware  | â­â­â­â­â­  | Parsear LaTeX semÃ¡nticamente  |
| 22  | GraphRAG LLM Completo  |  â­â­â­â­   | ExtracciÃ³n LLM 100% de chunks |
| 23  | Agente Tool Use        | â­â­â­â­â­  | Arquitectura agentic completa |
| 24  | Fine-tuning Embeddings | â­â­â­â­â­  | Adaptar embeddings al dominio |
| 25  | Neo4j                  |  â­â­â­â­   | Migrar grafo a Neo4j          |

Ver detalles en [future_work/ROADMAP_FINAL.md](future_work/ROADMAP_FINAL.md).

---

## 14. ConclusiÃ³n

LibrarAI es un sistema RAG completo y robusto que combina:

- **RecuperaciÃ³n de alta precisiÃ³n:** BÃºsqueda hÃ­brida + re-ranking + HyDE
- **OptimizaciÃ³n de costes:** MÃºltiples capas de cachÃ© (70-90% ahorro)
- **VerificaciÃ³n de calidad:** RAGAS + Critic + validaciÃ³n de citas
- **Robustez operacional:** Docker, logging estructurado, tests

El sistema estÃ¡ listo para uso en producciÃ³n como asistente de investigaciÃ³n para bibliotecas tÃ©cnicas de FÃ­sica, MatemÃ¡ticas y ComputaciÃ³n CuÃ¡ntica.

---

_Ãšltima actualizaciÃ³n: 7 de enero de 2026_
