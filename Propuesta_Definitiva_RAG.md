# ğŸ¯ Propuesta Definitiva: Sistema RAG AgÃ©ntico para Biblioteca TÃ©cnica

**VersiÃ³n:** 1.0  
**Fecha:** 2 de enero de 2026  
**Autor:** Asistente AI  
**Objetivo:** Generar apuntes tÃ©cnicos avanzados con mÃ¡xima fidelidad a fuentes originales

---

## 1. VisiÃ³n General del Sistema

### 1.1 Objetivo Principal

Construir un sistema de Retrieval-Augmented Generation (RAG) agÃ©ntico que permita:

- Generar apuntes tÃ©cnicos en Markdown/LaTeX basados en tu biblioteca personal
- Recuperar informaciÃ³n relevante por muy "escondida" que estÃ© en los documentos
- Citar fuentes con precisiÃ³n quirÃºrgica (documento + secciÃ³n exacta)
- Minimizar alucinaciones mediante grounding estricto

### 1.2 CaracterÃ­sticas Clave

| CaracterÃ­stica   | DescripciÃ³n                                                 |
| ---------------- | ----------------------------------------------------------- |
| **IntegraciÃ³n**  | CLI directa en terminal/VS Code (sin MCP)                   |
| **BÃºsqueda**     | HÃ­brida: semÃ¡ntica (vectores) + lÃ©xica (BM25) + grafo       |
| **Re-ranking**   | Cross-Encoder opcional para +15-25% precisiÃ³n               |
| **HyDE**         | Query expansion con documentos hipotÃ©ticos (+10-20% recall) |
| **EvaluaciÃ³n**   | Pipeline RAGAS: faithfulness, relevancy, precision          |
| **Cache**        | Embeddings cacheados: -70-90% costes, 0ms latencia          |
| **Filtrado**     | Por categorÃ­a/metadata para reducir ruido de dominios       |
| **Chunking**     | JerÃ¡rquico con auto-merge para contexto coherente           |
| **Citas**        | Rutas de encabezado (ej: `Libro > Cap 3 > Sec 3.2`)         |
| **VerificaciÃ³n** | EvaluaciÃ³n automÃ¡tica de fidelidad pre-entrega              |
| **Privacidad**   | Datos 100% locales, solo APIs para LLM de generaciÃ³n        |

### 1.3 Stack TecnolÃ³gico Recomendado

| Componente    | TecnologÃ­a                        | JustificaciÃ³n                                                 |
| ------------- | --------------------------------- | ------------------------------------------------------------- |
| Framework RAG | **LlamaIndex**                    | Soporte nativo para chunking jerÃ¡rquico, citations, workflows |
| Vector DB     | **Qdrant** (Docker)               | Escalable, filtrado por metadatos, HNSW eficiente             |
| Ãndice lÃ©xico | **BM25 via rank_bm25**            | Ligero, sin servidor, complementa bÃºsqueda semÃ¡ntica          |
| Re-ranker     | **Cross-Encoder (ms-marco)**      | Mejora precisiÃ³n post-fusiÃ³n, modelos locales eficientes      |
| EvaluaciÃ³n    | **RAGAS (LLM-as-judge)**          | MÃ©tricas estÃ¡ndar: faithfulness, relevancy, precision         |
| Cache         | **SQLite + LRU in-memory**        | Reduce costes 70-90%, elimina latencia en queries repetidas   |
| Embeddings    | **OpenAI text-embedding-3-large** | Mejor relaciÃ³n calidad/precio ($0.13/1M tokens)               |
| LLM SÃ­ntesis  | **Claude 3.5 Sonnet**             | 200k contexto, analÃ­tico, excelente en tÃ©cnico                |
| LLM Ruteo     | **GPT-4o-mini**                   | Ultra-econÃ³mico para clasificaciÃ³n y planificaciÃ³n            |
| Grafo         | **NetworkX** (en memoria)         | Suficiente para ~500 pÃ¡ginas, sin infraestructura extra       |

---

## 2. Arquitectura del Sistema

### 2.1 Diagrama de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USUARIO                                  â”‚
â”‚                    (Terminal / VS Code)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ CLI: ask_library "pregunta"
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA DE INTERFAZ                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ CLI Parser  â”‚  â”‚ Query       â”‚  â”‚ Output      â”‚              â”‚
â”‚  â”‚ (argparse)  â”‚  â”‚ Formatter   â”‚  â”‚ Renderer    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA AGÃ‰NTICA                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Router      â”‚  â”‚ Planner     â”‚  â”‚ Critic      â”‚              â”‚
â”‚  â”‚ (GPT-4o-m)  â”‚  â”‚ (Decompose) â”‚  â”‚ (Verify)    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA DE RECUPERACIÃ“N                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Vector      â”‚  â”‚ BM25        â”‚  â”‚ Graph       â”‚              â”‚
â”‚  â”‚ Retriever   â”‚  â”‚ Retriever   â”‚  â”‚ Traversal   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                          â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ HyDE        â”‚  â”‚ Fusion +    â”‚ â”€â”€â”€â–¶ â”‚ Re-Ranker   â”‚          â”‚
â”‚  â”‚ (opcional)  â”‚  â”‚ Auto-Merge  â”‚      â”‚ (opcional)  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA DE GENERACIÃ“N                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Context     â”‚  â”‚ LLM         â”‚  â”‚ Citation    â”‚              â”‚
â”‚  â”‚ Builder     â”‚  â”‚ (Claude)    â”‚  â”‚ Injector    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA DE ALMACENAMIENTO                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Qdrant      â”‚  â”‚ BM25 Index  â”‚  â”‚ Knowledge   â”‚              â”‚
â”‚  â”‚ (Vectores)  â”‚  â”‚ (Pickle)    â”‚  â”‚ Graph       â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Flujo de Datos

1. **Ingesta** (offline, una vez):

   - Markdown â†’ Parser â†’ Chunks jerÃ¡rquicos â†’ Embeddings â†’ Ãndices

2. **Consulta** (runtime):
   - Pregunta â†’ Router â†’ RecuperaciÃ³n hÃ­brida â†’ FusiÃ³n â†’ SÃ­ntesis â†’ Respuesta citada

---

## 3. IngenierÃ­a de Datos

### 3.1 PreparaciÃ³n de Documentos

Tu biblioteca ya estÃ¡ en Markdown (vÃ­a Mathpix), lo cual es ideal. Asegurar:

| Aspecto     | Requisito                           | VerificaciÃ³n                          |
| ----------- | ----------------------------------- | ------------------------------------- |
| Encabezados | JerarquÃ­a clara (`#`, `##`, `###`)  | Revisar que cada secciÃ³n tenga tÃ­tulo |
| FÃ³rmulas    | Delimitadas por `$$...$$` o `$...$` | No partir fÃ³rmulas entre chunks       |
| CÃ³digo      | En bloques ```                      | Tratar como unidad atÃ³mica            |
| Metadatos   | Nombre archivo = tÃ­tulo libro/paper | Consistencia en nomenclatura          |

### 3.2 Estrategia de Chunking JerÃ¡rquico

El sistema debe crear **3 niveles de fragmentos** vinculados entre sÃ­:

| Nivel                 | TamaÃ±o           | Contenido                        | Uso                             |
| --------------------- | ---------------- | -------------------------------- | ------------------------------- |
| **Macro** (Padre)     | 2048-4096 tokens | SecciÃ³n/subcapÃ­tulo completo     | Contexto amplio para respuestas |
| **Meso** (Intermedio) | 512 tokens       | PÃ¡rrafos relacionados            | Balance precisiÃ³n/contexto      |
| **Micro** (Hoja)      | 128-256 tokens   | Definiciones, teoremas, fÃ³rmulas | BÃºsqueda de alta precisiÃ³n      |

**Mecanismo Auto-Merge:**

- Se indexan los chunks **Micro** (mÃ¡xima densidad semÃ¡ntica)
- Si la bÃºsqueda recupera >50% de los hijos de un mismo padre â†’ devolver el padre completo
- Esto garantiza contexto coherente sin fragmentos inconexos

### 3.3 Metadatos por Chunk

Cada fragmento debe almacenar:

```
{
  "doc_id": "nielsen_chuang_qc",
  "doc_title": "Quantum Computation and Quantum Information",
  "header_path": "Cap 4 > Sec 4.2 > Teorema de No-ClonaciÃ³n",
  "parent_id": "chunk_macro_042",
  "level": "micro",
  "start_char": 45230,
  "end_char": 45890
}
```

La `header_path` es la **cita semÃ¡ntica** que reemplaza nÃºmeros de pÃ¡gina.

---

## 4. Sistema de RecuperaciÃ³n Avanzado

### 4.1 BÃºsqueda HÃ­brida (Vector + BM25)

| MÃ©todo        | Fortaleza                                               | Debilidad                 |
| ------------- | ------------------------------------------------------- | ------------------------- |
| **Vectorial** | Similitud conceptual ("red neuronal" â‰ˆ "deep learning") | Falla en tÃ©rminos exactos |
| **BM25**      | Coincidencia exacta ("Error 0x8004", "v2.1.4")          | No entiende sinÃ³nimos     |

**FusiÃ³n con Reciprocal Rank Fusion (RRF):**

- Recuperar top-50 de cada Ã­ndice
- Calcular score RRF: `1 / (k + rank)` con k=60
- Combinar y reordenar
- Pasar top-20 a reranker (opcional: Cohere Rerank)
- Seleccionar top-5 finales

### 4.2 Grafo de Conocimiento

Para tu biblioteca de fÃ­sica/computaciÃ³n cuÃ¡ntica, definir ontologÃ­a:

**Entidades:**

- `Algoritmo` (Shor, Grover, VQE...)
- `Protocolo` (BB84, E91, QKD...)
- `Concepto` (Entrelazamiento, Decoherencia...)
- `Autor` (Nielsen, Chuang, Preskill...)
- `Paper/Libro`

**Relaciones:**

- `MEJORA` (Algoritmo A mejora B)
- `DEPENDE_DE` (Protocolo usa Concepto)
- `CITA` (Paper X cita Paper Y)
- `DEFINE` (Libro define Concepto)

**Uso:** Cuando la bÃºsqueda vectorial encuentra un concepto, el grafo permite "saltar" a documentos relacionados aunque no compartan palabras clave.

### 4.3 Flujo de RecuperaciÃ³n AgÃ©ntica (Deep Research)

```
1. CLASIFICAR consulta y ASIGNAR PESOS DINÃMICOS:
   - Simple (definiciÃ³n directa) â†’ BÃºsqueda Ãºnica
   - Compleja (comparaciÃ³n, multi-concepto) â†’ Descomponer
   - Pesos segÃºn tipo detectado:
     * TÃ©rminos exactos (BB84, Shor): bm25=0.6, vector=0.3, graph=0.1
     * Conceptual: vector=0.5, bm25=0.3, graph=0.2
     * Relacional: graph=0.5, vector=0.3, bm25=0.2
     * Comparativa: vector=0.4, bm25=0.3, graph=0.3

2. Si compleja, DESCOMPONER en sub-preguntas:
   - "Compara BB84 con E91" â†’ ["Â¿QuÃ© es BB84?", "Â¿QuÃ© es E91?", "Diferencias"]

3. Para cada sub-pregunta, BUSCAR:
   a) (Opcional) HyDE: Generar documentos hipotÃ©ticos â†’ embedding multi-query
   b) Vector search (top-30)
   c) BM25 search (top-30)
   d) Graph traversal (si detecta entidad conocida)
   e) FusiÃ³n RRF â†’ top-10
   f) (Opcional) Re-ranking con Cross-Encoder â†’ top-k refinado

4. EVALUAR suficiencia (Critic):
   - Â¿Los fragmentos cubren la pregunta?
   - Â¿Hay contradicciones?
   - Â¿Falta algÃºn aspecto?

5. Si insuficiente, ITERAR:
   - Reformular query
   - Buscar en documentos conectados vÃ­a grafo
   - MÃ¡ximo 3 iteraciones

6. APLICAR Auto-Merge:
   - Consolidar chunks hermanos en padres

7. ENTREGAR contexto final al generador
```

---

## 5. GeneraciÃ³n con Citas

### 5.1 Estructura del Prompt

```
[SISTEMA]
Eres un asistente acadÃ©mico que genera apuntes tÃ©cnicos basÃ¡ndote
EXCLUSIVAMENTE en los documentos proporcionados.

Reglas:
1. Cada afirmaciÃ³n debe tener una cita [n] al fragmento que la respalda
2. Si la informaciÃ³n no estÃ¡ en los documentos, responde "No encontrado"
3. Usa formato Markdown con fÃ³rmulas LaTeX cuando sea apropiado
4. Preserva la precisiÃ³n tÃ©cnica de las fuentes

[DOCUMENTOS]
[1] {texto fragmento 1}
    Fuente: {doc_title} > {header_path}

[2] {texto fragmento 2}
    Fuente: {doc_title} > {header_path}

...

[PREGUNTA]
{pregunta del usuario}

[FORMATO DE RESPUESTA]
- Respuesta estructurada en Markdown
- Citas inline [n] para cada dato
- SecciÃ³n "Referencias" al final listando las fuentes usadas
```

### 5.2 VerificaciÃ³n Pre-Entrega (Critic)

Antes de mostrar la respuesta, un segundo LLM (o el mismo con diferente prompt) evalÃºa:

| Criterio        | Pregunta de EvaluaciÃ³n                                | AcciÃ³n si Falla                 |
| --------------- | ----------------------------------------------------- | ------------------------------- |
| **Fidelidad**   | Â¿Cada afirmaciÃ³n tiene cita y estÃ¡ en los fragmentos? | Eliminar afirmaciÃ³n sin soporte |
| **Completitud** | Â¿Se respondiÃ³ toda la pregunta?                       | Buscar mÃ¡s informaciÃ³n          |
| **Coherencia**  | Â¿Hay contradicciones entre fuentes?                   | SeÃ±alar discrepancia            |

Si fidelidad < 90%, regenerar respuesta o marcar secciones dudosas.

### 5.3 PolÃ­tica de AbstenciÃ³n

El sistema **debe abstenerse** de responder cuando:

- Score mÃ¡ximo de fragmentos recuperados < 0.65 (similitud baja)
- Critic detecta >2 afirmaciones sin soporte
- La pregunta estÃ¡ claramente fuera del dominio de la biblioteca

Respuesta en estos casos:

> "No he encontrado informaciÃ³n suficiente en la biblioteca para responder con certeza. Los documentos mÃ¡s cercanos son: [listar]. Â¿Deseas que busque de otra manera?"

---

## 6. EjecuciÃ³n de CÃ³digo y Diagramas

Para respuestas que requieran cÃ¡lculos, simulaciones o visualizaciones, el sistema incluye capacidad de ejecutar cÃ³digo de forma controlada.

### 6.1 Casos de Uso

| Tipo             | Ejemplo de Pregunta                         | AcciÃ³n del Sistema                              |
| ---------------- | ------------------------------------------- | ----------------------------------------------- |
| **GrÃ¡ficas**     | "Grafica la distribuciÃ³n de Boltzmann"      | Genera cÃ³digo matplotlib, ejecuta, inserta PNG  |
| **CÃ¡lculos**     | "Calcula la entropÃ­a de von Neumann para Ï" | Genera cÃ³digo NumPy, ejecuta, muestra resultado |
| **Diagramas**    | "Diagrama del protocolo BB84"               | Genera bloque Mermaid inline                    |
| **Simulaciones** | "Simula 1000 mediciones de un qubit"        | Genera cÃ³digo, ejecuta, muestra estadÃ­sticas    |

### 6.2 Arquitectura de Sandbox

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AGENTE RAG                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚ Detectar    â”‚  "Grafica..." / "Calcula..." / "Simula..." â”‚
â”‚  â”‚ necesidad   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚         â”‚                                                    â”‚
â”‚         â–¼                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Generar     â”‚â”€â”€â”€â”€â–¶â”‚         SANDBOX                 â”‚    â”‚
â”‚  â”‚ cÃ³digo      â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚ Docker container        â”‚    â”‚    â”‚
â”‚                      â”‚  â”‚ - Sin acceso a red      â”‚    â”‚    â”‚
â”‚                      â”‚  â”‚ - Timeout: 30s          â”‚    â”‚    â”‚
â”‚                      â”‚  â”‚ - RAM lÃ­mite: 512MB     â”‚    â”‚    â”‚
â”‚                      â”‚  â”‚ - Solo libs permitidas  â”‚    â”‚    â”‚
â”‚                      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚                      â”‚              â”‚                   â”‚    â”‚
â”‚                      â”‚              â–¼                   â”‚    â”‚
â”‚                      â”‚  stdout/stderr + archivos PNG   â”‚    â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                                                    â”‚
â”‚         â–¼                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚ Insertar    â”‚  ![grafica](outputs/fig_001.png)           â”‚
â”‚  â”‚ en respuestaâ”‚                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.3 LibrerÃ­as Permitidas en Sandbox

```python
ALLOWED_IMPORTS = [
    "numpy",
    "scipy",
    "matplotlib",
    "sympy",        # Para Ã¡lgebra simbÃ³lica
    "qutip",        # Para simulaciones cuÃ¡nticas
    "pandas",
    "math",
    "cmath",
]

BLOCKED = [
    "os", "sys", "subprocess", "socket",
    "requests", "urllib", "__import__"
]
```

### 6.4 Diagramas Mermaid

Para diagramas, el LLM genera directamente bloques Mermaid que VS Code renderiza:

````markdown
```mermaid
sequenceDiagram
    participant A as Alice
    participant B as Bob
    participant E as Eve
    A->>B: EnvÃ­a qubits en bases aleatorias
    B->>B: Mide en bases aleatorias
    A->>B: Anuncia bases usadas
    B->>A: Confirma coincidencias
    Note over A,B: Clave compartida
```
````

````

### 6.5 Consideraciones de Seguridad

| Riesgo | MitigaciÃ³n |
|--------|------------|
| CÃ³digo malicioso del LLM | Sandbox aislado, whitelist de imports |
| Bucles infinitos | Timeout estricto (30s) |
| Consumo excesivo de recursos | LÃ­mites de CPU/RAM en Docker |
| ExfiltraciÃ³n de datos | Sin acceso a red ni filesystem host |

---

## 7. Observabilidad y Logging

### 7.1 Capas de Logging

| Capa | QuÃ© se registra | Herramienta |
|------|-----------------|-------------|
| **Consultas** | Query original, timestamp, user_id | JSON logs |
| **RecuperaciÃ³n** | Chunks recuperados, scores, tiempo | JSON logs |
| **GeneraciÃ³n** | Tokens in/out, modelo usado, coste | JSON logs |
| **Errores** | Stack traces, queries fallidas | Python logging |

### 7.2 Estructura de Log por Consulta

```json
{
  "session_id": "2026-01-02_143522_abc123",
  "timestamp": "2026-01-02T14:35:22Z",
  "query": "Â¿QuÃ© es el teorema de no-clonaciÃ³n?",
  "query_type": "simple",
  "retrieval": {
    "vector_results": 30,
    "bm25_results": 28,
    "after_fusion": 10,
    "final_chunks": 5,
    "top_score": 0.89,
    "sources": ["nielsen_chuang", "preskill_notes"],
    "time_ms": 450
  },
  "generation": {
    "model": "claude-3-5-sonnet",
    "tokens_in": 3200,
    "tokens_out": 480,
    "time_ms": 2100,
    "cost_usd": 0.018
  },
  "verification": {
    "fidelity_score": 0.95,
    "citations_valid": 3,
    "citations_total": 3
  },
  "total_time_ms": 2800
}
````

### 7.3 Dashboard de MÃ©tricas (Opcional)

Para anÃ¡lisis agregado, se puede usar **Grafana + JSON logs** o una soluciÃ³n ligera:

```
ğŸ“Š MÃ‰TRICAS ÃšLTIMOS 7 DÃAS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Consultas totales:          247
Coste acumulado:            $9.38
Tiempo medio respuesta:     3.2s
Fidelidad media:            94.2%
Abstenciones:               12 (4.9%)

Top 5 documentos citados:
  1. Nielsen & Chuang (89 citas)
  2. Preskill Notes (45 citas)
  3. BB84 Paper (23 citas)
  ...
```

### 7.4 Herramientas de Observabilidad Avanzada

Para debugging detallado de flujos agÃ©nticos:

| Herramienta          | PropÃ³sito               | IntegraciÃ³n             |
| -------------------- | ----------------------- | ----------------------- |
| **LangFuse**         | Tracing de LLM calls    | SDK Python, self-hosted |
| **Phoenix (Arize)**  | VisualizaciÃ³n de traces | Open source             |
| **Weights & Biases** | Experimentos, evals     | Cloud (opcional)        |

---

## 8. Comparativa de Modelos LLM

### 8.1 Modelos para GeneraciÃ³n (SÃ­ntesis)

| Modelo                | Contexto | Precio Input | Precio Output | Calidad TÃ©cnica | RecomendaciÃ³n  |
| --------------------- | -------- | ------------ | ------------- | --------------- | -------------- |
| **Claude 3.5 Sonnet** | 200K     | $3/1M        | $15/1M        | â­â­â­â­â­      | **Principal**  |
| GPT-4o                | 128K     | $2.50/1M     | $10/1M        | â­â­â­â­â­      | Alternativa    |
| GPT-4o-mini           | 128K     | $0.15/1M     | $0.60/1M      | â­â­â­          | Ruteo/Planning |
| Claude 3 Haiku        | 200K     | $0.25/1M     | $1.25/1M      | â­â­â­          | VerificaciÃ³n   |
| Gemini 1.5 Pro        | 1M       | $2.50/1M     | $10/1M        | â­â­â­â­        | Contexto largo |
| **Llama 3.3 70B**     | 128K     | $0 (local)   | $0 (local)    | â­â­â­â­        | 100% offline   |

### 8.2 Modelos para Embeddings

| Modelo                     | Dimensiones           | Precio   | Calidad    | RecomendaciÃ³n      |
| -------------------------- | --------------------- | -------- | ---------- | ------------------ |
| **text-embedding-3-large** | 3072 (256 comprimido) | $0.13/1M | â­â­â­â­â­ | **Principal**      |
| text-embedding-3-small     | 1536                  | $0.02/1M | â­â­â­â­   | EconÃ³mico          |
| BGE-M3 (local)             | 1024                  | $0       | â­â­â­â­   | 100% offline       |
| Voyage-2                   | 1024                  | $0.10/1M | â­â­â­â­â­ | TÃ©cnico/cientÃ­fico |

### 8.3 ConfiguraciÃ³n Recomendada por Escenario

| Escenario          | LLM Principal     | LLM Ruteo      | Embeddings       | Coste/100 queries |
| ------------------ | ----------------- | -------------- | ---------------- | ----------------- |
| **Calidad mÃ¡xima** | Claude 3.5 Sonnet | GPT-4o-mini    | text-emb-3-large | ~$4.00            |
| **Equilibrado**    | GPT-4o            | GPT-4o-mini    | text-emb-3-small | ~$2.50            |
| **EconÃ³mico**      | Claude 3 Haiku    | Claude 3 Haiku | text-emb-3-small | ~$0.80            |
| **100% Local**     | Llama 3.3 70B     | Llama 3.3 8B   | BGE-M3           | ~$0 (hardware)    |

### 8.4 OpciÃ³n 100% Local (Sin APIs)

Si la privacidad total es prioritaria o quieres eliminar costes variables:

**Requisitos hardware:**

- GPU: 2Ã— RTX 4090 (48GB VRAM total) o 1Ã— A100 80GB
- RAM: 64GB mÃ­nimo
- Almacenamiento: SSD NVMe 500GB+

**Stack:**

- LLM: Llama 3.3 70B vÃ­a **vLLM** (servidor de inferencia optimizado)
- Embeddings: **BGE-M3** vÃ­a sentence-transformers
- Vector DB: Qdrant (sin cambios)

**Trade-offs:**
| Aspecto | Con APIs | 100% Local |
|---------|----------|------------|
| Calidad | â­â­â­â­â­ | â­â­â­â­ |
| Latencia | 2-5s | 5-15s |
| Coste variable | ~$0.04/query | $0 |
| Coste fijo | $0 | ~$200-500/mes (electricidad, amortizaciÃ³n) |
| Privacidad | Datos salen a API | 100% local |

---

## 9. IntegraciÃ³n CLI

### 9.1 Comandos Disponibles

| Comando                            | DescripciÃ³n                     | Ejemplo                                             |
| ---------------------------------- | ------------------------------- | --------------------------------------------------- |
| `ask_library "pregunta"`           | Consulta principal              | `ask_library "Â¿QuÃ© es el teorema de no-clonaciÃ³n?"` |
| `ask_library --verbose "pregunta"` | Muestra proceso de bÃºsqueda     | Ver quÃ© fragmentos se recuperaron                   |
| `ask_library --deep "pregunta"`    | Fuerza modo Deep Research       | Para preguntas complejas                            |
| `ask_library --sources "pregunta"` | Solo mostrar fuentes relevantes | Sin generar respuesta                               |
| `ingest_library`                   | Re-indexar biblioteca completa  | Tras aÃ±adir nuevos documentos                       |
| `ingest_library --update`          | IndexaciÃ³n incremental          | Solo documentos nuevos/modificados                  |

### 9.2 Formato de Salida

```markdown
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ RESPUESTA â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

El **teorema de no-clonaciÃ³n** establece que es imposible crear una
copia exacta de un estado cuÃ¡ntico arbitrario desconocido[1].

MatemÃ¡ticamente, no existe un operador unitario $U$ tal que:
$$U|\psi\rangle|0\rangle = |\psi\rangle|\psi\rangle$$
para todo $|\psi\rangle$[1][2].

Este resultado tiene implicaciones fundamentales para la criptografÃ­a
cuÃ¡ntica, ya que garantiza que un espÃ­a no puede copiar qubits sin
ser detectado[3].

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“š REFERENCIAS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[1] Nielsen & Chuang - Quantum Computation > Cap 12 > Sec 12.1
[2] Preskill Notes > Cap 3 > Teorema 3.1  
[3] BB84 Paper > Sec 2 > Security Analysis

â±ï¸ Tiempo: 3.2s | ğŸ“Š Fragmentos consultados: 47 | ğŸ’° Coste: $0.02
```

### 9.3 IntegraciÃ³n con VS Code

**OpciÃ³n A: Task en tasks.json**

- Crear task que ejecute `ask_library` con input del usuario
- Atajo de teclado personalizado (ej: `Ctrl+Shift+L`)

**OpciÃ³n B: Alias en terminal**

- AÃ±adir al `.bashrc`/`.zshrc`: `alias ask='python /ruta/ask_library.py'`
- Usar directamente: `ask "mi pregunta"`

**OpciÃ³n C: Script wrapper**

- Script que abre resultado en nuevo archivo `.md` para preview

---

## 10. IndexaciÃ³n Incremental

### 10.1 Problema a Resolver

Al aÃ±adir nuevos documentos a la biblioteca, no queremos re-indexar todo desde cero. El sistema debe detectar quÃ© cambiÃ³ y procesar solo lo necesario.

### 10.2 Estrategia con Hashing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROCESO DE INGESTA                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Para cada archivo .md en /data/markdown/                       â”‚
â”‚                                                                 â”‚
â”‚  1. Calcular hash SHA-256 del contenido                         â”‚
â”‚  2. Comparar con hash almacenado en manifest.json               â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Â¿Existe?    â”‚ Â¿Hash igual?  â”‚ AcciÃ³n                     â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ No          â”‚ -             â”‚ INDEXAR (nuevo documento)  â”‚   â”‚
â”‚  â”‚ SÃ­          â”‚ SÃ­            â”‚ SKIP (sin cambios)         â”‚   â”‚
â”‚  â”‚ SÃ­          â”‚ No            â”‚ RE-INDEXAR (modificado)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  3. Actualizar manifest.json con nuevo hash                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.3 Estructura del Manifest

```json
{
  "last_updated": "2026-01-02T14:30:00Z",
  "documents": {
    "books/nielsen_chuang.md": {
      "hash": "a1b2c3d4e5f6...",
      "chunks": 245,
      "indexed_at": "2026-01-01T10:00:00Z"
    },
    "papers/bb84.md": {
      "hash": "f6e5d4c3b2a1...",
      "chunks": 32,
      "indexed_at": "2026-01-01T10:05:00Z"
    }
  }
}
```

### 10.4 Comandos de Ingesta

| Comando                    | Comportamiento                       |
| -------------------------- | ------------------------------------ |
| `ingest_library`           | Re-indexa TODO (ignora hashes)       |
| `ingest_library --update`  | Solo documentos nuevos/modificados   |
| `ingest_library --dry-run` | Muestra quÃ© se indexarÃ­a sin hacerlo |

---

## 11. Estructura del Proyecto

```
quantum_library_rag/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.yaml          # ConfiguraciÃ³n general
â”‚   â””â”€â”€ ontology.yaml          # DefiniciÃ³n de entidades/relaciones
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ markdown/              # Biblioteca de documentos .md
â”‚   â”‚   â”œâ”€â”€ books/
â”‚   â”‚   â””â”€â”€ papers/
â”‚   â””â”€â”€ processed/             # Cache de chunks procesados
â”‚
â”œâ”€â”€ indices/
â”‚   â”œâ”€â”€ qdrant/                # Base de datos vectorial
â”‚   â”œâ”€â”€ bm25_index.pkl         # Ãndice BM25 serializado
â”‚   â””â”€â”€ knowledge_graph.gpickle # Grafo NetworkX
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ parser.py          # Markdown parser con header_path
â”‚   â”‚   â”œâ”€â”€ chunker.py         # Chunking jerÃ¡rquico
â”‚   â”‚   â””â”€â”€ indexer.py         # CreaciÃ³n de Ã­ndices
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ vector_retriever.py
â”‚   â”‚   â”œâ”€â”€ bm25_retriever.py
â”‚   â”‚   â”œâ”€â”€ graph_retriever.py
â”‚   â”‚   â”œâ”€â”€ fusion.py          # RRF + Auto-merge
â”‚   â”‚   â”œâ”€â”€ reranker.py        # Cross-Encoder re-ranking
â”‚   â”‚   â”œâ”€â”€ cache.py           # Cache de embeddings
â”‚   â”‚   â””â”€â”€ hyde.py            # HyDE Query Expansion
â”‚   â”‚
â”‚   â”œâ”€â”€ generation/
â”‚   â”‚   â”œâ”€â”€ prompt_builder.py
â”‚   â”‚   â”œâ”€â”€ synthesizer.py     # Llamada a LLM
â”‚   â”‚   â””â”€â”€ citation_injector.py
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ router.py          # ClasificaciÃ³n + pesos dinÃ¡micos
â”‚   â”‚   â”œâ”€â”€ planner.py         # DescomposiciÃ³n
â”‚   â”‚   â””â”€â”€ critic.py          # VerificaciÃ³n
â”‚   â”‚
â”‚   â””â”€â”€ cli/
â”‚       â”œâ”€â”€ ask_library.py     # Punto de entrada CLI
â”‚       â””â”€â”€ ingest_library.py
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ sessions/              # Logs de cada consulta
â”‚
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ figures/               # GrÃ¡ficas generadas (si aplica)
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_retrieval.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## 12. EstimaciÃ³n de Costes

### 12.1 Costes de Puesta en Marcha (CAPEX)

**Supuestos para tu biblioteca:**

- ~500 pÃ¡ginas totales (11 libros + 10 papers)
- ~375,000 tokens (750 tokens/pÃ¡gina promedio)
- ~3,000 chunks (125 tokens/chunk promedio)

| Concepto                           | CÃ¡lculo                 |      Coste |
| ---------------------------------- | ----------------------- | ---------: |
| **Embeddings (indexaciÃ³n)**        | 375k tokens Ã— $0.13/1M  |  **$0.05** |
| **ExtracciÃ³n grafo (GPT-4o-mini)** | ~500k tokens Ã— $0.15/1M |  **$0.08** |
| **Qdrant (local Docker)**          | Self-hosted             |  **$0.00** |
| **BM25 (en memoria)**              | Sin coste               |  **$0.00** |
| **Desarrollo/Config**              | Tu tiempo               |   Variable |
|                                    |                         |            |
| **TOTAL SETUP**                    |                         | **~$0.15** |

> ğŸ’¡ El coste de infraestructura es prÃ¡cticamente nulo porque todo corre local excepto las APIs de embedding/LLM.

### 12.2 Costes por Uso (OPEX)

**Escenario: 100 consultas**

| Tipo de Consulta  | % del Total | Tokens In | Tokens Out | Modelo            | Coste/consulta |
| ----------------- | :---------: | --------: | ---------: | ----------------- | -------------: |
| **Simple**        |     60%     |     3,000 |        500 | Claude 3.5 Sonnet |         $0.016 |
| **Compleja**      |     30%     |    15,000 |      1,000 | Claude 3.5 Sonnet |         $0.060 |
| **Deep Research** |     10%     |    25,000 |      1,500 | Claude 3.5 Sonnet |         $0.098 |
| **Ruteo (todas)** |    100%     |       500 |         50 | GPT-4o-mini       |        $0.0001 |

**CÃ¡lculo para 100 consultas:**

| Componente                | CÃ¡lculo       |       Coste |
| ------------------------- | ------------- | ----------: |
| 60 consultas simples      | 60 Ã— $0.016   |       $0.96 |
| 30 consultas complejas    | 30 Ã— $0.060   |       $1.80 |
| 10 consultas deep         | 10 Ã— $0.098   |       $0.98 |
| 100 ruteos                | 100 Ã— $0.0001 |       $0.01 |
|                           |               |             |
| **TOTAL 100 consultas**   |               |   **$3.75** |
| **Promedio por consulta** |               | **$0.0375** |

### 12.3 Resumen de Costes

| PerÃ­odo                 |       Coste | Notas                    |
| ----------------------- | ----------: | ------------------------ |
| **Setup inicial**       |      ~$0.15 | Una sola vez             |
| **100 consultas**       |      ~$3.75 | ~$0.04/consulta promedio |
| **500 consultas/mes**   |     ~$18.75 | Uso intensivo            |
| **Uso diario (10/dÃ­a)** | ~$11.25/mes | Uso moderado             |

> ğŸ“Š **Comparativa:** Una suscripciÃ³n a ChatGPT Plus cuesta $20/mes. Con este sistema, tendrÃ­as ~530 consultas/mes por el mismo precio, pero con acceso directo a TU biblioteca y citas precisas.

---

## 13. GuÃ­a de ImplementaciÃ³n

### 13.1 Requisitos Previos

**Software:**

- Python 3.10+
- Docker (para Qdrant)
- Git

**APIs necesarias:**

- OpenAI API Key (embeddings + GPT-4o-mini)
- Anthropic API Key (Claude 3.5 Sonnet)

**Hardware recomendado:**

- 8GB RAM mÃ­nimo (16GB recomendado)
- 10GB espacio disco para Ã­ndices
- CPU moderno (no requiere GPU)

### 13.2 Pasos de ImplementaciÃ³n

```
FASE 1: INFRAESTRUCTURA (DÃ­a 1)
â”œâ”€â”€ 1.1 Crear estructura de carpetas
â”œâ”€â”€ 1.2 Configurar entorno virtual Python
â”œâ”€â”€ 1.3 Instalar dependencias (requirements.txt)
â”œâ”€â”€ 1.4 Levantar Qdrant con Docker
â””â”€â”€ 1.5 Configurar API keys en variables de entorno

FASE 2: INGESTA (DÃ­a 2-3)
â”œâ”€â”€ 2.1 Implementar parser Markdown con header_path
â”œâ”€â”€ 2.2 Implementar chunker jerÃ¡rquico (3 niveles)
â”œâ”€â”€ 2.3 Generar embeddings e indexar en Qdrant
â”œâ”€â”€ 2.4 Construir Ã­ndice BM25
â”œâ”€â”€ 2.5 Extraer entidades/relaciones para grafo
â””â”€â”€ 2.6 Serializar Ã­ndices para persistencia

FASE 3: RECUPERACIÃ“N (DÃ­a 4-5)
â”œâ”€â”€ 3.1 Implementar vector retriever con Qdrant
â”œâ”€â”€ 3.2 Implementar BM25 retriever
â”œâ”€â”€ 3.3 Implementar fusiÃ³n RRF
â”œâ”€â”€ 3.4 Implementar auto-merge de chunks
â”œâ”€â”€ 3.5 Implementar graph traversal
â””â”€â”€ 3.6 Tests unitarios de recuperaciÃ³n

FASE 4: GENERACIÃ“N (DÃ­a 6-7)
â”œâ”€â”€ 4.1 DiseÃ±ar prompt templates
â”œâ”€â”€ 4.2 Implementar context builder
â”œâ”€â”€ 4.3 Implementar llamada a Claude
â”œâ”€â”€ 4.4 Implementar citation injector
â”œâ”€â”€ 4.5 Implementar critic/verificador
â””â”€â”€ 4.6 Tests de generaciÃ³n

FASE 5: AGENTES (DÃ­a 8-9)
â”œâ”€â”€ 5.1 Implementar router (clasificaciÃ³n)
â”œâ”€â”€ 5.2 Implementar planner (descomposiciÃ³n)
â”œâ”€â”€ 5.3 Implementar loop de Deep Research
â””â”€â”€ 5.4 Tests end-to-end

FASE 6: CLI E INTEGRACIÃ“N (DÃ­a 10)
â”œâ”€â”€ 6.1 Implementar CLI con argparse
â”œâ”€â”€ 6.2 Formatear salida Markdown
â”œâ”€â”€ 6.3 AÃ±adir modo verbose
â”œâ”€â”€ 6.4 Configurar alias/shortcuts
â””â”€â”€ 6.5 DocumentaciÃ³n de uso
```

### 13.3 Dependencias Principales

```
# requirements.txt (versiones indicativas)

# Framework RAG
llama-index>=0.10.0
llama-index-vector-stores-qdrant>=0.1.0
llama-index-embeddings-openai>=0.1.0

# Vector DB
qdrant-client>=1.7.0

# BÃºsqueda lÃ©xica
rank-bm25>=0.2.2

# Grafos
networkx>=3.2

# LLMs
openai>=1.10.0
anthropic>=0.18.0

# Utilidades
pyyaml>=6.0
python-dotenv>=1.0.0
rich>=13.0  # Para output bonito en CLI
```

### 13.4 ConfiguraciÃ³n Recomendada

```yaml
# config/settings.yaml

embedding:
  model: "text-embedding-3-large"
  dimensions: 1536 # Puede reducirse a 256 para velocidad

chunking:
  micro_size: 200
  meso_size: 512
  macro_size: 2048
  overlap: 50

retrieval:
  vector_top_k: 30
  bm25_top_k: 30
  fusion_top_k: 10
  final_top_k: 5
  auto_merge_threshold: 0.5 # 50% de hijos = devolver padre

generation:
  model: "claude-3-5-sonnet-20241022"
  temperature: 0.3
  max_tokens: 2000

routing:
  model: "gpt-4o-mini"

verification:
  enabled: true
  fidelity_threshold: 0.9
```

---

## 14. MÃ©tricas de Ã‰xito

### 14.1 KPIs del Sistema

| MÃ©trica                         | Objetivo                              | MediciÃ³n                      |
| ------------------------------- | ------------------------------------- | ----------------------------- |
| **PrecisiÃ³n de citas**          | >95% afirmaciones con cita vÃ¡lida     | Muestreo manual               |
| **Recall de informaciÃ³n**       | >90% de info relevante recuperada     | Tests con preguntas conocidas |
| **Latencia**                    | <5s consultas simples, <15s complejas | Logging automÃ¡tico            |
| **Tasa de abstenciÃ³n correcta** | <5% falsos "no encontrado"            | Muestreo manual               |
| **Coste por consulta**          | <$0.05 promedio                       | Tracking de tokens            |

### 14.2 Tests de ValidaciÃ³n

Crear un conjunto de 20-30 preguntas de prueba con respuestas conocidas:

1. **Preguntas factuales simples** (ej: "Â¿CuÃ¡ntos qubits tiene el algoritmo de Shor para factorizar N?")
2. **Preguntas que requieren sÃ­ntesis** (ej: "Compara BB84 con E91")
3. **Preguntas sobre conexiones** (ej: "Â¿QuÃ© relaciÃ³n hay entre el teorema de no-clonaciÃ³n y QKD?")
4. **Preguntas fuera de dominio** (ej: "Â¿CuÃ¡l es la capital de Francia?") - debe abstenerse

---

## 15. EvoluciÃ³n Futura

### 15.1 Mejoras Potenciales (v2.0)

| Mejora                    | Beneficio                             | Complejidad |
| ------------------------- | ------------------------------------- | ----------- |
| Cache de respuestas       | Reducir costes en preguntas repetidas | Baja        |
| Fine-tuning de embeddings | Mejorar precisiÃ³n en dominio          | Alta        |
| UI web local (Streamlit)  | Interfaz mÃ¡s amigable                 | Media       |
| RAG multimodal            | Indexar figuras/diagramas de libros   | Alta        |
| Exportar a Obsidian       | IntegraciÃ³n con PKM                   | Baja        |

### 15.2 Escalabilidad

El sistema estÃ¡ diseÃ±ado para escalar:

- **MÃ¡s documentos:** Qdrant maneja millones de vectores
- **MÃ¡s usuarios:** PodrÃ­as exponer como API REST local
- **MÃ¡s dominios:** AÃ±adir nuevas ontologÃ­as al grafo

---

## 16. ConclusiÃ³n

Esta propuesta combina las mejores estrategias identificadas en el anÃ¡lisis previo:

âœ… **De Propuesta C:** Arquitectura visual, comparativa de LLMs, flujo de 8 etapas  
âœ… **De Propuesta G:** Enfoque 100% local para datos, estructura de proyecto, CLI  
âœ… **De Propuesta A:** GraphRAG con ontologÃ­a, Deep Research Loop  
âœ… **De Propuesta B:** AnÃ¡lisis CLI vs MCP (eligiendo CLI), deduplicaciÃ³n por hash  
âœ… **De Propuesta E:** Cascada de bÃºsqueda en 3 niveles, auto-merge

El resultado es un sistema que:

- **Encuentra** informaciÃ³n por muy escondida que estÃ© (bÃºsqueda hÃ­brida + grafo)
- **Cita** con precisiÃ³n quirÃºrgica (rutas de encabezado)
- **Verifica** antes de responder (critic + abstenciÃ³n)
- **Cuesta** ~$0.04/consulta en promedio
- **Se integra** naturalmente en tu flujo de trabajo (CLI en terminal/VS Code)

**Tiempo estimado de implementaciÃ³n:** 10-15 dÃ­as para un desarrollador experimentado.

---

_Documento generado el 2 de enero de 2026_
